{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12112921-d35c-463d-83b0-651fe9a29548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 08:12:32.470406: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-08 08:12:32.549657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-08 08:12:32.567130: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-08 08:12:32.571558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-08 08:12:32.626493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06627f1d",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122cbbb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf37c28",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 08:12:35.203363: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-05-08 08:12:35.203657: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: nihad-IdeaPad-3-15ITL6\n",
      "2025-05-08 08:12:35.203660: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: nihad-IdeaPad-3-15ITL6\n",
      "2025-05-08 08:12:35.203802: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 550.144.3\n",
      "2025-05-08 08:12:35.203812: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 550.120.0\n",
      "2025-05-08 08:12:35.203815: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:252] kernel version 550.120.0 does not match DSO version 550.144.3 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "  y_pred_classes = K.argmax(y_pred, axis=-1)\n",
    "  true_positives = K.sum(K.cast(y_pred_classes[y_true == 1] == 1, 'float32'))\n",
    "  possible_positives = K.sum(K.cast(y_true == 1, 'float32'))\n",
    "  return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "  y_pred_classes = K.argmax(y_pred, axis=-1)\n",
    "  true_negatives = K.sum(K.cast(y_pred_classes[y_true == 0] == 0, 'float32'))\n",
    "  possible_negatives = K.sum(K.cast(y_true == 0, 'float32'))\n",
    "  return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "from tensorflow.keras.metrics import F1Score\n",
    "\n",
    "f1_metric = F1Score()\n",
    "\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "accuracy = SparseCategoricalAccuracy(name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de8d68",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70b493d",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_signals():\n",
    "\n",
    "    path = \"../data/training2017/\"\n",
    "\n",
    "    records = os.listdir(path)\n",
    "\n",
    "    records = [record for record in records if record.endswith('.mat')]\n",
    "\n",
    "    records = [os.path.splitext(record)[0] for record in records]\n",
    "\n",
    "    records.sort()\n",
    "\n",
    "    signals = [wfdb.rdrecord(record_name=path+record).p_signal for record in records]\n",
    "\n",
    "    fs = wfdb.rdrecord(record_name=path+records[0]).fs\n",
    "\n",
    "    signals_flat = []\n",
    "    for signal in signals:\n",
    "        signal_flat = [sample[0] for sample in signal]\n",
    "        signal_flat = np.array(signal_flat)\n",
    "        signals_flat.append(signal_flat)\n",
    "\n",
    "    signals_flat = np.asarray(signals_flat, dtype=np.ndarray)\n",
    "    \n",
    "    return signals_flat\n",
    "\n",
    "signals_flat = load_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcefe89",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73308759",
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "def plot_psd_heatmap(signals, fs=300):\n",
    "    \"\"\"\n",
    "    Plots a power spectral density (PSD) heatmap using periodogram.\n",
    "    \n",
    "    Parameters:\n",
    "        signals (array-like): List or array of 1D signals (same length).\n",
    "        fs (float): Sampling frequency in Hz.\n",
    "    \"\"\"\n",
    "    signals = np.array(signals.tolist(), dtype=np.float32)  # convert object array to float\n",
    "    num_signals = len(signals)\n",
    "    \n",
    "    # Compute PSD for each signal\n",
    "    freqs, psd = periodogram(signals, fs=fs, axis=1)\n",
    "\n",
    "    # Convert to dB scale (optional but common)\n",
    "    psd_db = 10 * np.log10(psd + 1e-12)  # avoid log(0)\n",
    "    #psd_db = psd\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(psd_db, aspect='auto', origin='lower',\n",
    "               extent=[freqs[0], freqs[-1], 0, num_signals],\n",
    "               cmap='viridis')\n",
    "    plt.colorbar(label='Power Spectral Density (dB/Hz)')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Signal Index')\n",
    "    plt.title('PSD Heatmap using Periodogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c481c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Modifying signal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711e59e5",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cut_signals_shortest(signals_flat):\n",
    "     # Get the minimum length across all signals\n",
    "    lengths = [len(signal) for signal in signals_flat]\n",
    "    min_length = min(lengths)\n",
    "    \n",
    "    # Create the middle slices for each signal\n",
    "    signals_middle = []\n",
    "    for signal in signals_flat:\n",
    "        signal_length = len(signal)\n",
    "        \n",
    "        # Calculate the start and end indices for the middle of each signal\n",
    "        start = (signal_length // 2 - min_length // 2)\n",
    "        end = start + min_length\n",
    "        \n",
    "        # Slice the signal to keep the middle part\n",
    "        signals_middle.append(signal[start:end])\n",
    "    \n",
    "    # Convert the list of signals to a NumPy array\n",
    "    signals_middle = np.array(signals_middle)\n",
    "    \n",
    "    return signals_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddc17423",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_center_5s(signals, target_length=600):\n",
    "    \"\"\"\n",
    "    Extract central 5 seconds (600 samples at 120Hz) from each signal.\n",
    "    If signal is shorter than 600, pad with zeros (centered).\n",
    "    \n",
    "    Parameters:\n",
    "        signals: array-like of 1D numpy arrays (downsampled ECG signals)\n",
    "        target_length: number of samples to extract (default is 600 for 5s at 120Hz)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray of shape (num_signals, target_length)\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "\n",
    "    for signal in signals:\n",
    "        sig_len = len(signal)\n",
    "\n",
    "        if sig_len >= target_length:\n",
    "            start = (sig_len - target_length) // 2\n",
    "            segment = signal[start:start + target_length]\n",
    "        else:\n",
    "            pad_len = target_length - sig_len\n",
    "            pad_left = pad_len // 2\n",
    "            pad_right = pad_len - pad_left\n",
    "            segment = np.pad(signal, (pad_left, pad_right), mode='constant')\n",
    "\n",
    "        processed.append(segment)\n",
    "\n",
    "    return np.array(processed, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86692001",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Per-signal z-score normalization (recommended for ECG)\n",
    "# signals_short = (signals_short - signals_short.mean(axis=1, keepdims=True)) / (signals_short.std(axis=1, keepdims=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80596c87",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c944278f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "\n",
    "    data = pd.read_csv(filepath_or_buffer=\"../data/training2017/REFERENCE-v3.csv\", names=[\"signal_name\", \"label\"])\n",
    "\n",
    "    data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes\n",
    "\n",
    "    data = data.drop([\"signal_name\"], axis=1)\n",
    "\n",
    "    y = np.array(data[\"label\"])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d1416",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Removing extra classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844a0438",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_extra_classes(X, y):\n",
    "\n",
    "    classes_to_remove = [2, 3]\n",
    "\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Before removing \\n\")\n",
    "    for c, count in zip(classes, counts):\n",
    "        print(f\"Class {c}: {count} samples\")\n",
    "\n",
    "\n",
    "    mask = ~np.isin(y, classes_to_remove)\n",
    "\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    print(\"\\nAfter removing \\n\")\n",
    "    for c, count in zip(classes, counts):\n",
    "        print(f\"Class {c}: {count} samples\")\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba17bd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Normalisation (-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93139527",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def normalize_to_minus1_1(signals):\n",
    "    norm_signals = []\n",
    "    for x in signals:\n",
    "        x_min = np.min(x)\n",
    "        x_max = np.max(x)\n",
    "        if x_max != x_min:\n",
    "            x_norm = 2 * (x - x_min) / (x_max - x_min) - 1\n",
    "        else:\n",
    "            x_norm = np.zeros_like(x)  # Avoid division by zero\n",
    "        norm_signals.append(x_norm)\n",
    "    return np.array(norm_signals, dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef1c1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e975b92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28276358",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def get_class_weights(y):\n",
    "    # Convert one-hot labels to integers\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    return class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e88fc",
   "metadata": {},
   "source": [
    "### Models, hyperparameter optimization and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742a779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee5aa5a2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_model_conv1D(input_shape):\n",
    "    input_layer = layers.Input(shape=(input_shape, 1))\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv1D(32, kernel_size=7, padding=\"same\")(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv1D(128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Optional: Dropout for regularization\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    output_layer = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b061dd1",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, ReLU, Input, Softmax\n",
    "\n",
    "def build_custom_vgg_1d(input_length=3000, num_classes=4):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_length, 1)))  # 1D signal input\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(Conv1D(64, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(64, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Conv1D(128, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(128, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(Conv1D(256, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(256, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(256, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 5\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(Conv1D(512, kernel_size=3, padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 6, 7, 8: Fully connected layers\n",
    "    model.add(Dense(1024, activation='relu'))  # Layer 6\n",
    "    model.add(Dense(1024, activation='relu'))  # Layer 7\n",
    "    model.add(Dense(256, activation='relu'))   # Layer 8\n",
    "\n",
    "    # Layer 9: Output softmax\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3943c503",
   "metadata": {
    "code_folding": [
     3,
     11
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(x, filters, kernel_size, blocks, pool_stride):\n",
    "    for _ in range(blocks):\n",
    "        x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=2, strides=pool_stride, padding='same')(x)\n",
    "    return x\n",
    "\n",
    "def build_dual_stream_model(input_length=3000, num_classes=2):\n",
    "    input_layer = Input(shape=(input_length, 1))\n",
    "\n",
    "    # Stream 1 (kernel size = 3)\n",
    "    s1 = conv_block(input_layer, 64, 3, 2, 3)    # Layer 1\n",
    "    s1 = conv_block(s1, 128, 3, 2, 3)            # Layer 2\n",
    "    s1 = conv_block(s1, 256, 3, 3, 2)            # Layer 3\n",
    "    s1 = conv_block(s1, 512, 3, 3, 2)            # Layer 4\n",
    "    s1 = conv_block(s1, 512, 3, 3, 2)            # Layer 5\n",
    "    s1 = Flatten()(s1)\n",
    "\n",
    "    # Stream 2 (kernel size = 5 for first two layers, then same as stream 1)\n",
    "    s2 = conv_block(input_layer, 64, 5, 2, 3)    # Layer 1\n",
    "    s2 = conv_block(s2, 128, 5, 2, 3)            # Layer 2\n",
    "    s2 = conv_block(s2, 256, 3, 3, 2)            # Layer 3\n",
    "    s2 = conv_block(s2, 512, 3, 3, 2)            # Layer 4\n",
    "    s2 = conv_block(s2, 512, 3, 3, 2)            # Layer 5\n",
    "    s2 = Flatten()(s2)\n",
    "\n",
    "    # Merge\n",
    "    merged = Concatenate()([s1, s2])\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(1024, activation='relu')(merged)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ce510ed",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv1D\n",
    "\n",
    "class MaskedConv1D(Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(MaskedConv1D, self).__init__()\n",
    "        self.conv = Conv1D(filters, kernel_size, padding='same', **kwargs)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = self.conv(inputs)\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(tf.expand_dims(mask, axis=-1), x.dtype)\n",
    "            x *= mask\n",
    "        return x\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3892d490",
   "metadata": {
    "code_folding": [
     6,
     14
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Masking, ReLU, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    Dense, Concatenate, BatchNormalization\n",
    ")\n",
    "\n",
    "def masked_conv_block(x, filters, kernel_size, blocks, pool_stride):\n",
    "    for _ in range(blocks):\n",
    "        x = MaskedConv1D(filters, kernel_size)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=2, strides=pool_stride, padding='same')(x)\n",
    "    return x\n",
    "\n",
    "def build_model(input_length=600, trial=None, tune=False,\n",
    "                dense_units=512, learning_rate=1e-3, batch_size=32):\n",
    "    input_layer = Input(shape=(input_length, 1))\n",
    "    masked_input = Masking(mask_value=0.0)(input_layer)\n",
    "\n",
    "    # If tuning, get hyperparameters from trial\n",
    "    if tune and trial is not None:\n",
    "        dense_units = trial.suggest_int(\"dense_units\", 128, 1024, step=128)\n",
    "        learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "\n",
    "    # Stream 1\n",
    "    s1 = masked_conv_block(masked_input, 64, 3, 2, 3)\n",
    "    s1 = masked_conv_block(s1, 128, 3, 2, 3)\n",
    "    s1 = masked_conv_block(s1, 256, 3, 3, 2)\n",
    "    s1 = masked_conv_block(s1, 512, 3, 3, 2)\n",
    "    s1 = GlobalAveragePooling1D()(s1)\n",
    "\n",
    "    # Stream 2\n",
    "    s2 = masked_conv_block(masked_input, 64, 5, 2, 3)\n",
    "    s2 = masked_conv_block(s2, 128, 5, 2, 3)\n",
    "    s2 = masked_conv_block(s2, 256, 3, 3, 2)\n",
    "    s2 = masked_conv_block(s2, 512, 3, 3, 2)\n",
    "    s2 = GlobalAveragePooling1D()(s2)\n",
    "\n",
    "    merged = Concatenate()([s1, s2])\n",
    "    x = Dense(dense_units, activation='relu')(merged)\n",
    "    x = Dense(dense_units, activation='relu')(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model, batch_size  # Also return batch_size for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "452daf11",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Load and preprocess data\n",
    "    X = X_data  # shape (N, 600, 1)\n",
    "    y = y_data  # shape (N,) with 0 or 1\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    \n",
    "    X_train, y_train = RandomOverSampler().fit_resample(X_train, y_train)\n",
    "\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "    model, batch_size = build_model(input_length=600, trial=trial, tune=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=10,\n",
    "                        batch_size=trial.suggest_categorical(\"batch_size\", [32, 64]),\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_preds = (model.predict(X_val) > 0.5).astype(int)\n",
    "    val_acc = accuracy_score(y_val, val_preds)\n",
    "    return 1.0 - val_acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ef400",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9452ace3",
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, one_hot_labels=True):\n",
    "    \"\"\"\n",
    "    Evaluates a Keras model on a test set and prints:\n",
    "    - Confusion matrix\n",
    "    - Per-class sensitivity and specificity\n",
    "    - Overall accuracy\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Keras model\n",
    "    - X_test: Test input data (NumPy array)\n",
    "    - y_test: True labels (one-hot encoded or integer)\n",
    "    - one_hot_labels: Set to True if y_test is one-hot encoded\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert predictions and labels to class indices\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    if one_hot_labels:\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "    else:\n",
    "        y_true = y_test\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Sensitivity & Specificity\n",
    "    num_classes = cm.shape[0]\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = cm[i, i]\n",
    "        FN = np.sum(cm[i, :]) - TP\n",
    "        FP = np.sum(cm[:, i]) - TP\n",
    "        TN = np.sum(cm) - (TP + FN + FP)\n",
    "\n",
    "        sens = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        spec = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "        sensitivity.append(sens)\n",
    "        specificity.append(spec)\n",
    "\n",
    "        print(f\"Class {i}: Sensitivity = {sens:.4f}, Specificity = {spec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "793f840a",
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_kfold_cross_validation(X, y, build_model_fn, num_folds=10, epochs=10, batch_size=32):\n",
    "    \"\"\"\n",
    "    Run k-fold cross-validation for a Keras model.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Input features of shape (samples, length).\n",
    "        y (np.ndarray): Labels of shape (samples,) or one-hot encoded.\n",
    "        build_model_fn (function): A function that returns a compiled Keras model.\n",
    "        num_folds (int): Number of folds for cross-validation.\n",
    "        epochs (int): Training epochs per fold.\n",
    "        batch_size (int): Training batch size.\n",
    "        one_hot (bool): If True, converts labels to one-hot encoding.\n",
    "\n",
    "    Returns:\n",
    "        List of validation accuracies per fold.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\nğŸ“˜ Fold {fold}/{num_folds}\")\n",
    "\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = build_model_fn()\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0)\n",
    "\n",
    "        val_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"âœ… Fold {fold} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    avg_accuracy = np.mean(val_accuracies)\n",
    "    print(f\"\\nğŸ¯ Average Validation Accuracy: {avg_accuracy:.4f}\")\n",
    "    return val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e4c42",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a22b1a",
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def low_pass_filter(X, fs_original=300, cutoff_freq=60):\n",
    "    # Design the low-pass filter (Butterworth filter)\n",
    "    nyquist = 0.5 * fs_original  # Nyquist frequency\n",
    "    normal_cutoff = cutoff_freq / nyquist  # Normalize the cutoff frequency\n",
    "    \n",
    "    # Create the low-pass filter\n",
    "    b, a = butter(4, normal_cutoff, btype='low', analog=False)\n",
    "    \n",
    "    # Apply the low-pass filter to each signal (row) in X\n",
    "    filtered_X = []\n",
    "    for signal in X:\n",
    "        # Apply the filter to each signal\n",
    "        filtered_signal = filtfilt(b, a, signal)\n",
    "        \n",
    "        # Trim any extra edge artifacts (in case of filter edge effects)\n",
    "        filtered_signal = filtered_signal[:len(signal)]\n",
    "        \n",
    "        filtered_X.append(filtered_signal)\n",
    "    \n",
    "    # Return as a list of arrays (each signal with its own length)\n",
    "    return filtered_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6718f9bb",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def downsample_signal(X, fs_original=300, fs_new=120):\n",
    "    downsampled_X = []\n",
    "    \n",
    "    # Down-sample each signal (row) in X individually\n",
    "    for signal in X:\n",
    "        # Calculate the down-sample factor\n",
    "        downsample_factor = fs_original // fs_new\n",
    "        \n",
    "        # Down-sample the signal based on the calculated factor\n",
    "        downsampled_signal = signal[::downsample_factor]\n",
    "        downsampled_X.append(downsampled_signal)\n",
    "    \n",
    "    # Return as a list of downsampled signals (each signal with its own length)\n",
    "    return downsampled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f6e68f",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_fft(signal, fs=300):\n",
    "    \"\"\"\n",
    "    Calculate and plot the FFT of a signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: The input signal (1D array)\n",
    "    - fs: The sampling frequency (default 300 Hz)\n",
    "    \"\"\"\n",
    "    # Number of samples in the signal\n",
    "    n = len(signal)\n",
    "    \n",
    "    # Compute the FFT\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    \n",
    "    # Compute the frequencies corresponding to the FFT bins\n",
    "    freqs = np.fft.fftfreq(n, 1/fs)\n",
    "    \n",
    "    # Take the absolute value of the FFT (magnitude)\n",
    "    fft_magnitude = np.abs(fft_signal)\n",
    "    \n",
    "    # Only keep the positive half of the spectrum (real frequencies)\n",
    "    positive_freqs = freqs[:n//2]\n",
    "    positive_fft_magnitude = fft_magnitude[:n//2]\n",
    "    \n",
    "    # Plot the FFT magnitude vs frequency\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(positive_freqs, positive_fft_magnitude)\n",
    "    plt.title('FFT of Signal')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c309f0",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f776cde5",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5854d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing \n",
      "\n",
      "Class 0: 758 samples\n",
      "Class 1: 5076 samples\n",
      "Class 2: 2415 samples\n",
      "Class 3: 279 samples\n",
      "\n",
      "After removing \n",
      "\n",
      "Class 0: 758 samples\n",
      "Class 1: 5076 samples\n"
     ]
    }
   ],
   "source": [
    "X = signals_flat\n",
    "y = load_labels()\n",
    "\n",
    "X, y = remove_extra_classes(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89252579",
   "metadata": {},
   "source": [
    "### 2 stream 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ede61c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing \n",
      "\n",
      "Class 0: 758 samples\n",
      "Class 1: 5076 samples\n",
      "\n",
      "After removing \n",
      "\n",
      "Class 0: 758 samples\n",
      "Class 1: 5076 samples\n"
     ]
    }
   ],
   "source": [
    "X, y = remove_extra_classes(X, y)\n",
    "\n",
    "X_filtered = low_pass_filter(X=X)\n",
    "\n",
    "X_downsampled = downsample_signal(X=X_filtered)\n",
    "\n",
    "X_normalised = normalize_to_minus1_1(X_downsampled)\n",
    "\n",
    "signal_seconds = 5\n",
    "sampling_freq = 120\n",
    "signal_len = signal_seconds * sampling_freq\n",
    "X = extract_center_5s(signals=X_normalised, target_length=signal_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "598a072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = RandomOverSampler().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d272f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train.tolist(), dtype=np.float32)  \n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = np.array(X_test.tolist(), dtype=np.float32)  \n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e34a854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_229' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_233' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_591' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_581' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_592' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_582' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 266ms/step - accuracy: 0.5927 - loss: 0.8064 - val_accuracy: 0.0000e+00 - val_loss: 1.2133\n",
      "Epoch 2/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 261ms/step - accuracy: 0.7405 - loss: 0.5564 - val_accuracy: 0.3791 - val_loss: 0.9369\n",
      "Epoch 3/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 257ms/step - accuracy: 0.7836 - loss: 0.4978 - val_accuracy: 0.3687 - val_loss: 1.8753\n",
      "Epoch 4/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 257ms/step - accuracy: 0.8218 - loss: 0.3786 - val_accuracy: 0.6540 - val_loss: 0.6633\n",
      "Epoch 5/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 259ms/step - accuracy: 0.8803 - loss: 0.2789 - val_accuracy: 0.9773 - val_loss: 0.1205\n",
      "Epoch 6/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 257ms/step - accuracy: 0.9084 - loss: 0.2290 - val_accuracy: 0.9638 - val_loss: 0.1165\n",
      "Epoch 7/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 271ms/step - accuracy: 0.9103 - loss: 0.2160 - val_accuracy: 0.6718 - val_loss: 0.8338\n",
      "Epoch 8/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 262ms/step - accuracy: 0.9195 - loss: 0.2068 - val_accuracy: 0.9362 - val_loss: 0.2027\n",
      "Epoch 9/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 261ms/step - accuracy: 0.9303 - loss: 0.1719 - val_accuracy: 0.9871 - val_loss: 0.0851\n",
      "Epoch 10/10\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 261ms/step - accuracy: 0.9358 - loss: 0.1717 - val_accuracy: 0.9693 - val_loss: 0.1426\n"
     ]
    }
   ],
   "source": [
    "input_size = len(X_train[0])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# model = make_model_conv1D(input_shape=input_size)\n",
    "# model = build_custom_vgg_1d(input_length=input_size, num_classes=2)\n",
    "# model = build_dual_stream_model(input_length=input_size, num_classes=2)\n",
    "model, batch_size = build_model(input_length=input_size, trial=None, tune=False,\n",
    "                dense_units=640, learning_rate=0.0021803189997713648, batch_size=32)\n",
    "\n",
    "# # model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs = run_kfold_cross_validation(X=X, y=y, build_model_fn=build_custom_vgg_1d, num_folds=10, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f3b6d346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n",
      "Confusion Matrix:\n",
      " [[147  18]\n",
      " [ 87 915]]\n",
      "\n",
      "Overall Accuracy: 0.9100\n",
      "Class 0: Sensitivity = 0.8909, Specificity = 0.9132\n",
      "Class 1: Sensitivity = 0.9132, Specificity = 0.8909\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model=model, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3bcd2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee907655",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 06:24:12,698] A new study created in memory with name: no-name-381f80c4-0193-4a1c-b8c7-769b91905e98\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_133' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_137' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_351' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_341' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_352' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_342' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 06:34:58,580] Trial 0 finished with value: 0.4764353041988003 and parameters: {'dense_units': 1024, 'lr': 0.0005146277970474038, 'batch_size': 32}. Best is trial 0 with value: 0.4764353041988003.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_141' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_145' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_371' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_361' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_372' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_362' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 06:58:09,055] Trial 1 finished with value: 0.07626392459297349 and parameters: {'dense_units': 640, 'lr': 0.00014879220988337817, 'batch_size': 64}. Best is trial 1 with value: 0.07626392459297349.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_149' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_153' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_391' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_381' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_392' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_382' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 07:08:44,935] Trial 2 finished with value: 0.0856898029134533 and parameters: {'dense_units': 512, 'lr': 0.0002673203090819144, 'batch_size': 64}. Best is trial 1 with value: 0.07626392459297349.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_157' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_161' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_411' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_401' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_412' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_402' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 07:42:30,379] Trial 3 finished with value: 0.07197943444730082 and parameters: {'dense_units': 640, 'lr': 0.0021803189997713648, 'batch_size': 32}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_165' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_169' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_431' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_421' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_432' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_422' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 09:06:50,564] Trial 4 finished with value: 0.08311910882604967 and parameters: {'dense_units': 128, 'lr': 0.0003152058582765441, 'batch_size': 32}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_173' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_177' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_451' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_441' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_452' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_442' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 09:22:50,752] Trial 5 finished with value: 0.39331619537275064 and parameters: {'dense_units': 128, 'lr': 0.002642705947807724, 'batch_size': 32}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_181' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_185' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_471' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_461' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_472' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_462' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 09:34:49,287] Trial 6 finished with value: 0.078834618680377 and parameters: {'dense_units': 512, 'lr': 0.0013557178513799591, 'batch_size': 64}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_189' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_193' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_491' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_481' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_492' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_482' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 09:46:53,205] Trial 7 finished with value: 0.11139674378748932 and parameters: {'dense_units': 896, 'lr': 0.005257346380436745, 'batch_size': 64}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_197' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_201' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_511' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_501' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_512' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_502' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 09:58:44,096] Trial 8 finished with value: 0.1053984575835476 and parameters: {'dense_units': 1024, 'lr': 0.0007271749576338845, 'batch_size': 64}. Best is trial 3 with value: 0.07197943444730082.\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_205' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_209' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_531' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_521' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_532' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_522' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 10:10:05,391] Trial 9 finished with value: 0.13024850042844904 and parameters: {'dense_units': 128, 'lr': 0.008809275311094086, 'batch_size': 32}. Best is trial 3 with value: 0.07197943444730082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Accuracy: 92.80%\n",
      "  Params:  {'dense_units': 640, 'lr': 0.0021803189997713648, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "X_data = X\n",
    "y_data = y\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Accuracy: {:.2f}%\".format((1.0 - study.best_value) * 100))\n",
    "print(\"  Params: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2bd80",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "208e6d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3d29d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_591' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_581' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_592' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_582' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_233' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_229' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by each of 5 principal components:\n",
      "PC1: 0.8849\n",
      "PC2: 0.1120\n",
      "PC3: 0.0012\n",
      "PC4: 0.0007\n",
      "PC5: 0.0004\n",
      "\n",
      "Total information coverage (5 PCs): 0.9992\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Step 1: Extract output of last FC layer (before sigmoid)\n",
    "feature_layer = model.layers[-2].output\n",
    "feature_extractor = Model(inputs=model.input, outputs=feature_layer)\n",
    "\n",
    "# Step 2: Get features for entire test set\n",
    "features = feature_extractor.predict(X_test, verbose=0)  # Shape (N, D)\n",
    "\n",
    "# Step 3: Apply PCA to reduce to 5 components\n",
    "pca = PCA(n_components=5)\n",
    "reduced_features = pca.fit_transform(features)\n",
    "\n",
    "# Step 4: Print explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.sum(explained_variance)\n",
    "\n",
    "print(\"Explained variance by each of 5 principal components:\")\n",
    "for i, ratio in enumerate(explained_variance, start=1):\n",
    "    print(f\"PC{i}: {ratio:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal information coverage (5 PCs): {cumulative_variance:.4f}\")\n",
    "\n",
    "# Step 5: Optional 2D scatter plot for PC1 vs PC2\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(reduced_features[y_test == 0, 0], reduced_features[y_test == 0, 1],\n",
    "            label=\"Normal\", alpha=0.6, color=\"green\")\n",
    "plt.scatter(reduced_features[y_test == 1, 0], reduced_features[y_test == 1, 1],\n",
    "            label=\"AF\", alpha=0.6, color=\"red\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA of Last FC Layer Features (Test Set)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "db6686ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def extract_features_by_layer_indices(model, X, y, layer_indices):\n",
    "    \"\"\"\n",
    "    Extracts features from specific Conv/FC layer indices (based on Conv/FC count, not layer index).\n",
    "    Returns a dict {layer_name: reduced_features}\n",
    "    \"\"\"\n",
    "    features_dict = {}\n",
    "    conv_fc_count = 0\n",
    "    selected_outputs = []\n",
    "    selected_names = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (tf.keras.layers.Conv1D, tf.keras.layers.Dense, MaskedConv1D)):\n",
    "            conv_fc_count += 1\n",
    "            if conv_fc_count in layer_indices:\n",
    "                selected_outputs.append(layer.output)\n",
    "                selected_names.append(f\"Layer{conv_fc_count}_{layer.name}\")\n",
    "\n",
    "    feature_model = Model(inputs=model.input, outputs=selected_outputs)\n",
    "    features_list = feature_model.predict(X, verbose=0)\n",
    "\n",
    "    for name, feats in zip(selected_names, features_list):\n",
    "        if len(feats.shape) == 3:\n",
    "            feats = tf.reduce_mean(feats, axis=1).numpy()\n",
    "        elif len(feats.shape) == 1:\n",
    "            feats = feats.reshape(-1, 1)\n",
    "\n",
    "        if feats.shape[1] >= 5:\n",
    "            pca = PCA(n_components=5)\n",
    "            reduced = pca.fit_transform(feats)\n",
    "            coverage = np.sum(pca.explained_variance_ratio_)\n",
    "            features_dict[name] = (reduced, coverage)\n",
    "            print(f\"{name}: {coverage:.4f} variance explained by 5 PCs\")\n",
    "        else:\n",
    "            print(f\"{name}: Skipped PCA â€” not enough features (got {feats.shape[1]})\")\n",
    "\n",
    "    return features_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "46e2ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_591' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_581' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_592' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'conv1d_582' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_233' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/nihad/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/layers/layer.py:940: UserWarning: Layer 'max_pooling1d_229' (of type MaxPooling1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2_dense_93: Skipped PCA â€” not enough features (got 1)\n"
     ]
    }
   ],
   "source": [
    "# Use test data\n",
    "layer_indices = [2, 4, 7, 10, 13, 16]\n",
    "features_by_layer = extract_features_by_layer_indices(model, X_test, y_test, layer_indices)\n",
    "\n",
    "# Optional: plot PCA of one layer\n",
    "# reduced_feats, _ = features_by_layer['Layer16_dense_2']  # Example\n",
    "# plt.scatter(reduced_feats[y_test == 0, 0], reduced_feats[y_test == 0, 1], label='Normal', alpha=0.6)\n",
    "# plt.scatter(reduced_feats[y_test == 1, 0], reduced_feats[y_test == 1, 1], label='AF', alpha=0.6)\n",
    "# plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.legend(); plt.title(\"Layer 16 PCA\"); plt.grid(True); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "15f31081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6314382 , -0.6357738 , -0.63880193, ..., -0.67383444,\n",
       "        -0.6703082 , -0.6679079 ],\n",
       "       [-0.4654801 , -0.4807946 , -0.49080408, ..., -0.31707922,\n",
       "        -0.31356508, -0.31359303],\n",
       "       [-0.7084222 , -0.7368452 , -0.7368704 , ..., -0.66566336,\n",
       "        -0.6618546 , -0.6632435 ],\n",
       "       ...,\n",
       "       [-0.18685642, -0.20766897, -0.21703391, ...,  0.13423714,\n",
       "         0.14159389,  0.15712494],\n",
       "       [-0.17392287, -0.17463478, -0.21200258, ..., -0.46309105,\n",
       "        -0.45886764, -0.4543725 ],\n",
       "       [-0.21736747, -0.21707392, -0.21679112, ..., -0.19282693,\n",
       "        -0.19435845, -0.19739065]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b54177",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9668cd2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52de483c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_shape = (max_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fdfaa611",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model_with_masking(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Masking layer to handle padded values (assuming padding value is 0)\n",
    "    masked_inputs = layers.Masking(mask_value=0.0)(inputs)\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm_out = layers.LSTM(64, return_sequences=False)(masked_inputs)\n",
    "    \n",
    "    # Dense output layer\n",
    "    outputs = layers.Dense(4, activation='softmax')(lstm_out)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8a9cc9fe",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 18:17:06.803660: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 15/179\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m25:59\u001b[0m 10s/step - accuracy: 0.3955 - loss: 1.3753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m model_with_masking\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model_with_masking\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_with_masking = create_model_with_masking(input_shape)\n",
    "\n",
    "\n",
    "model_with_masking.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_with_masking.fit(X_train, y_train, epochs=10, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398bf87",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### without masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "879521f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model_without_masking(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm_out = layers.LSTM(64, return_sequences=False)(inputs)\n",
    "    \n",
    "    # Dense output layer\n",
    "    outputs = layers.Dense(4, activation='softmax')(lstm_out)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c4927da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1386s\u001b[0m 8s/step - accuracy: 0.5612 - loss: 1.1012\n",
      "Epoch 2/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42623s\u001b[0m 239s/step - accuracy: 0.5951 - loss: 0.9894\n",
      "Epoch 3/10\n",
      "\u001b[1m175/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m31s\u001b[0m 8s/step - accuracy: 0.5929 - loss: 0.9877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m model_without_masking\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model_without_masking\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/zavrsni_master/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_without_masking = create_model_without_masking(input_shape)\n",
    "\n",
    "\n",
    "model_without_masking.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_without_masking.fit(X_train, y_train, epochs=10, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e1a560d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.3877 - sparse_categorical_accuracy: 0.2661\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3864 - sparse_categorical_accuracy: 0.2737\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3860 - sparse_categorical_accuracy: 0.2548\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3854 - sparse_categorical_accuracy: 0.2684\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3848 - sparse_categorical_accuracy: 0.2725\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3859 - sparse_categorical_accuracy: 0.2677\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3842 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3846 - sparse_categorical_accuracy: 0.2719\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3852 - sparse_categorical_accuracy: 0.2757\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3858 - sparse_categorical_accuracy: 0.2701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c36fc0b3500>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# Assuming 'create_model_with_masking' is defined as in the previous message\n",
    "\n",
    "# Generate synthetic training data\n",
    "num_samples = 1000\n",
    "max_sequence_length = 50\n",
    "num_features = 1  # Single feature per timestep\n",
    "num_classes = 4  # Number of output classes\n",
    "\n",
    "# Random sequences with varying lengths\n",
    "X_train = [np.random.rand(np.random.randint(1, max_sequence_length + 1), num_features) for _ in range(num_samples)]\n",
    "y_train = np.random.randint(0, num_classes, size=num_samples)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "X_train_padded = np.array([np.pad(seq, ((0, max_sequence_length - len(seq)), (0, 0)), mode='constant') if len(seq) < max_sequence_length else seq[:max_sequence_length] for seq in X_train])\n",
    "\n",
    "# Define the model\n",
    "input_shape = (max_sequence_length, num_features)\n",
    "model_with_masking = create_model_with_masking(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model_with_masking.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    metrics=[SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_with_masking.fit(X_train_padded, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
